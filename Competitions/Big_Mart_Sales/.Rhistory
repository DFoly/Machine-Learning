ggplot(Data, aes(x = FUEL_AMOUNT, fill = factor(FRAUD))) + geom_bar()
ggplot(Data, aes(x = MED_ASSESSMENT, fill = factor(FRAUD))) + geom_bar()
ggplot(Data, aes(x = MED_CONDITION_SATISFIED, fill = factor(FRAUD))) + geom_bar()
summary(Data$MED_CONDITION_SATISFIED)
str(Data$MED_CONDITION_SATISFIED)
head(Data$MED_CONDITION_SATISFIED)
View(Data)
ggplot(Data, aes(x = factor(MED_CONDITION_SATISFIED), fill = factor(FRAUD))) + geom_bar()
library(Amelia)
missmap(train, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
missmap(Data, main="Fraud Data missing values",
col=c("blue", "red"), legend=FALSE)
summary(Data)
View(Data)
Data[Data$DELAY == 0,]
ggplot(Data, aes(x = Data$DELAY == 0)) + geom_barplot()
ggplot(Data, aes(x = Data$DELAY == 0)) + geom_boxplot()
ggplot(Data, aes(x = Data$DELAY == 0)) + geom_bar()
ggplot(Data, aes(x = Data$DELAY == 0, fill = factor(FRAUD))) + geom_bar()
Data[Data$NO_DEP == 0,]
View(Data)
summary(Data$MEANS_FROM_EMP)
ggplot(Data, aes(x = factor(FRAUD), y =  MEANS_FROM_EMP)) +
geom_boxplot() + geom_hline(aes(yintercept = mean(MEANS_FROM_EMP)),
linetype = 'dashed', lwd = 2)
Data$MEANS_FROM_EMP <- scale(Data$MEANS_FROM_EMP)
ggplot(Data, aes(x = factor(FRAUD), y =  MEANS_FROM_EMP)) +
geom_boxplot() + geom_hline(aes(yintercept = mean(MEANS_FROM_EMP)),
linetype = 'dashed', lwd = 2)
View(Data)
Data$gp <- runif(dim(Data)[1])
trainingSet <- subset(Data, Data$gp > 0.1)
testSet <- subset(Data,Data$gp <= 0.1)
reg1 <- glm(FRAUD ~ MEANS_FROM_EMP + DELAY + NO_DEP +
FUEL_AMOUNT + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg1)
View(Data)
Data$MED_ASSESSMENT <- as.factor(Data$MED_ASSESSMENT)
Data$MED_CONDITION_SATISFIED <- as.factor(Data$MED_CONDITION_SATISFIED)
reg1 <- glm(FRAUD ~ MEANS_FROM_EMP + DELAY + NO_DEP +
FUEL_AMOUNT + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg1)
Data$MEANS_NEW <- ifelse(Data$MEANS_FROM_EMP <= mean(Data$MEANS_FROM_EMP),1,0)
brks <- c(0,20,40,60)
Data$DELAY_RANGE <- cut(Data$DELAY, breaks = brks, include.lowest = T)
summary(Data$DELAY_RANGE )
summary(Data$FUEL_AMOUNT)
brks2 <- c(0,60,100,140)
Data$FUEL_NEW <- cut(Data$FUEL_AMOUNT, breaks = brks2, include.lowest = T)
summary(Data$FUEL_NEW)
ggplot(Data, aes(x =  NO_DEP, fill = factor(FRAUD))) + geom_bar()
ggplot(Data, aes(x =  factor(NO_DEP), fill = factor(FRAUD))) + geom_bar()
str(Data$NO_DEP)
Data$NO_DEP <- as.factor(Data$NO_DEP)
Data$gp <- runif(dim(Data)[1])
trainingSet <- subset(Data, Data$gp > 0.1)
testSet <- subset(Data,Data$gp <= 0.1)
reg2 <- glm(FRAUD ~ MEANS_NEW + DELAY_RANGE + NO_DEP +
FUEL_NEW + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg1)
reg2 <- glm(FRAUD ~ MEANS_NEW + DELAY_RANGE +
FUEL_NEW + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg1)
reg2 <- glm(FRAUD ~ MEANS_NEW + DELAY_RANGE +
FUEL_NEW + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg2)
reg2 <- glm(FRAUD ~ MEANS_NEW + DELAY_RANGE + NO_DEP +
FUEL_NEW + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg2)
Data$NO_DEP2 <- ifelse(Data$NO_DEP > 4,1,0)
Data$NO_DEP2 <- ifelse(as.numeric(Data$NO_DEP) > 4,1,0)
Data$NO_DEP2
Data$NO_DEP2 <- as.factor(Data$NO_DEP2)
Data$gp <- runif(dim(Data)[1])
trainingSet <- subset(Data, Data$gp > 0.1)
testSet <- subset(Data,Data$gp <= 0.1)
reg2 <- glm(FRAUD ~ MEANS_NEW + DELAY_RANGE + NO_DEP2 +
FUEL_NEW + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg2)
fit <- predict(reg1, newdata = testSet, type = 'response')
Data$gp <- runif(dim(Data)[1])
trainingSet <- subset(Data, Data$gp > 0.1)
testSet <- subset(Data,Data$gp <= 0.1)
View(testSet)
fit <- predict(reg2, newdata = testSet, type = 'response')
fit
fit
fit <- ifelse(fitted.results > 0.5,1,0)
fit <- ifelse(fit> 0.5,1,0)
misClasificError <- mean(fit != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError))
reg1 <- glm(FRAUD ~ MEANS_FROM_EMP + DELAY + NO_DEP +
FUEL_AMOUNT + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg1)
fit1 <- predict(reg1, newdata = testSet, type = 'response')
fit1 <- ifelse(fit> 0.5,1,0)
misClasificError1 <- mean(fit1 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError1))
print(paste('Accuracy',1-misClasificError))
misClasificError1 <- mean(fit1 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError1))
library(rpart)
library(party)
set.seed(333)
rf1 <- cforest(as.factor(FRAUD) ~ MEANS_NEW + DELAY_RANGE +
NO_DEP2 + FUEL_NEW + MED_ASSESSMENT +
MED_CONDITION_SATISFIED,
data = trainingSet,
controls=cforest_unbiased(ntree=2000, mtry=3))
fit2 <- predict(rf1, newdata = testSet, type = 'response')
fit2
misClasificError2 <- mean(fit2 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError2))
summary(rf1)
library(randomForest)
set.seed(111)
set.seed(111)
rf2 <- randomForest(as.factor(FRAUD) ~ MEANS_NEW + DELAY_RANGE +
NO_DEP2 + FUEL_NEW + MED_ASSESSMENT +
MED_CONDITION_SATISFIED,
data = trainingSet,
importance = TRUE,
ntree = 2000)
varImpPlot(rf2)
fit3 <- predict(rf2, newdata = testSet, type = 'response')
fit3
misClasificError3 <- mean(fit3 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError3))
print(paste('Accuracy',1-misClasificError3))
print(paste('Accuracy',1-misClasificError))
fit1
cor(Data[,unlist(lapply(Data, is.numeric))], FRAUD)
cor(Data[,unlist(lapply(Data, is.numeric))], Data$FRAUD)
reg1 <- glm(FRAUD ~ MEANS_FROM_EMP + DELAY + NO_DEP +
FUEL_AMOUNT + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg1)
fit1 <- predict(reg1, newdata = testSet, type = 'response')
misClasificError1 <- mean(fit1 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError1))
reg1 <- glm(FRAUD ~ MEANS_FROM_EMP + DELAY +
FUEL_AMOUNT + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg1)
fit1 <- predict(reg1, newdata = testSet, type = 'response')
misClasificError1 <- mean(fit1 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError1))
fit1
fit1 <- ifelse(fit1 > 0.5,1,0)
misClasificError1 <- mean(fit1 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError1))
reg1 <- glm(FRAUD ~ MEANS_FROM_EMP + DELAY + NO_DEP
FUEL_AMOUNT + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg1)
fit1 <- predict(reg1, newdata = testSet, type = 'response')
fit1 <- ifelse(fit1 > 0.5,1,0)
misClasificError1 <- mean(fit1 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError1))
print(paste('Accuracy',1-misClasificError2))
Data$gp <- runif(dim(Data)[1])
trainingSet <- subset(Data, Data$gp > 0.1)
testSet <- subset(Data,Data$gp <= 0.1)
reg2 <- glm(FRAUD ~ MEANS_NEW + DELAY_RANGE + NO_DEP2 +
FUEL_NEW + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg2)
```{r}
fit <- predict(reg2, newdata = testSet, type = 'response')
fit <- ifelse(fit> 0.5,1,0)
misClasificError <- mean(fit != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError))
reg2 <- glm(FRAUD ~ MEANS_NEW + DELAY_RANGE + NO_DEP2 +
FUEL_NEW + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg2)
fit <- predict(reg2, newdata = testSet, type = 'response')
fit <- ifelse(fit> 0.5,1,0)
misClasificError <- mean(fit != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError))
reg1 <- glm(FRAUD ~ MEANS_FROM_EMP + DELAY + NO_DEP
FUEL_AMOUNT + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg1)
fit1 <- predict(reg1, newdata = testSet, type = 'response')
fit1 <- ifelse(fit1 > 0.5,1,0)
misClasificError1 <- mean(fit1 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError1))
rf2 <- randomForest(as.factor(FRAUD) ~ MEANS_NEW + DELAY_RANGE +
NO_DEP2 + FUEL_NEW + MED_ASSESSMENT +
MED_CONDITION_SATISFIED,
data = trainingSet,
importance = TRUE,
ntree = 2000)
fit3 <- predict(rf2, newdata = testSet, type = 'response')
misClasificError3 <- mean(fit3 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError3))
rf1 <- cforest(as.factor(FRAUD) ~ MEANS_NEW + DELAY_RANGE +
NO_DEP2 + FUEL_NEW + MED_ASSESSMENT +
MED_CONDITION_SATISFIED,
data = trainingSet,
controls=cforest_unbiased(ntree=2000, mtry=3))
fit4 <- predict(rf1, newdata = testSet, type = 'response')
misClasificError4 <- mean(fit4 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError4))
train_control <- trainControl(method = 'cv', number = 10)
library(caret)
train_control <- trainControl(method = 'cv', number = 10)
grid <- expand.grid(.fL=c(0), .usekernel=c(FALSE))
getModelInfo()
model <- train(FRAUD ~ MEANS_NEW + DELAY_RANGE + NO_DEP2 +
FUEL_NEW + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data=trainingSet, trControl=train_control,
method="rf", tuneGrid=grid)
model <- train(as.factor(FRAUD) ~ MEANS_NEW + DELAY_RANGE + NO_DEP2 +
FUEL_NEW + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data=trainingSet, trControl=train_control,
method="rf", tuneGrid=grid)
formula = s.factor(FRAUD) ~ MEANS_NEW + DELAY_RANGE +
NO_DEP2 + FUEL_NEW + MED_ASSESSMENT +
MED_CONDITION_SATISFIED
train_control <- trainControl(method = 'cv', number = 10)
modelLog = train(formula, data=trainingSet, method="glm", family=binomial,
trControl=train_control)
formula = as.factor(FRAUD) ~ MEANS_NEW + DELAY_RANGE +
NO_DEP2 + FUEL_NEW + MED_ASSESSMENT +
MED_CONDITION_SATISFIED
modelLog = train(formula, data=trainingSet, method="glm", family=binomial,
trControl=train_control)
print(modelLog)
train_control2 <- trainControl(method = 'cv', number = 10)
modelLog2 = train(formula, data=trainingSet, method="rf",
trControl=train_control)
print(modelLog2)
Data$gp <- runif(dim(Data)[1])
trainingSet <- subset(Data, Data$gp > 0.1)
testSet <- subset(Data,Data$gp <= 0.1)
reg1 <- glm(FRAUD ~ MEANS_FROM_EMP + DELAY + NO_DEP +
FUEL_AMOUNT + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg1)
fit1 <- predict(reg1, newdata = testSet, type = 'response')
fit1 <- ifelse(fit1 > 0.5,1,0)
misClasificError1 <- mean(fit1 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError1))
reg2 <- glm(FRAUD ~ MEANS_NEW + DELAY_RANGE + NO_DEP2 +
FUEL_NEW + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg2)
fit <- predict(reg2, newdata = testSet, type = 'response')
fit <- ifelse(fit> 0.5,1,0)
misClasificError <- mean(fit != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError))
set.seed(111)
rf2 <- randomForest(as.factor(FRAUD) ~ MEANS_FROM_EMP + DELAY + NO_DEP +
FUEL_AMOUNT + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet,
importance = TRUE,
ntree = 2000)
varImpPlot(rf2)
fit3 <- predict(rf2, newdata = testSet, type = 'response')
misClasificError3 <- mean(fit3 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError3))
set.seed(333)
rf1 <- cforest(as.factor(FRAUD) ~ MEANS_FROM_EMP + DELAY + NO_DEP +
FUEL_AMOUNT + MED_ASSESSMENT + MED_CONDITION_SATISFIED,
data = trainingSet,
controls=cforest_unbiased(ntree=2000, mtry=3))
fit4 <- predict(rf1, newdata = testSet, type = 'response')
misClasificError4 <- mean(fit4 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError4))
reg5 <- glm(FRAUD ~ MEANS_FROM_EMP + DELAY + NO_DEP +
FUEL_AMOUNT + MED_CONDITION_SATISFIED,
data = trainingSet, family =  binomial(link = 'logit'))
summary(reg5)
summary(reg1)
d
fit1 <- predict(reg5, newdata = testSet, type = 'response')
fit1 <- ifelse(fit1 > 0.5,1,0)
misClasificError1 <- mean(fit1 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError1))
print(paste('Accuracy',1-misClasificError1))
fit1 <- predict(reg1, newdata = testSet, type = 'response')
fit1 <- ifelse(fit1 > 0.5,1,0)
misClasificError1 <- mean(fit1 != testSet$FRAUD)
print(paste('Accuracy',1-misClasificError1))
amazon_baby <- read.csv("C:/Users/dfoley/Dropbox/Machine Learning/PythonCoursera/Classification/Week1/amazon_baby.csv")
View(amazon_baby)
library(tm)
Products = amazon_baby
amazon_baby = NULL
head(Products)
summary(Products)
View(Products)
Products[[13]]
Products[[13]
Products[13]
Products[13,]
Products[13,1]
removePunctuation(Products[13,1])
Products <- read.csv("C:/Users/dfoley/Dropbox/Machine Learning/PythonCoursera/Classification/Week1/amazon_baby.csv" stringsAsFactors = FALSE)
Products <- read.csv("C:/Users/dfoley/Dropbox/Machine Learning/PythonCoursera/Classification/Week1/amazon_baby.csv", stringsAsFactors = FALSE)
summary(Products)
Products[13,1]
removePunctuation(Products[13,1])
removePunctuation(Products$review)
Products$review_clean <- removePunctuation(Products$review)
Products$review_clean[1,1]
Products$review_clean[[1]]
review_text <- paste(Products$review_clean, collapse = ' ')
review_source <- VectorSource(review_text)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus,stripWhitespace)
corpus <- tm_map(corpus,removeWords, stopwords('english'))
corpus <- Corpus(review_source)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus,stripWhitespace)
corpus <- tm_map(corpus,removeWords, stopwords('english'))
dtm <- DocumentTermMatrix(corpus)
head(dtm)
dtm[,1]
dtm2 <- as.matrix(dtm)
frequency <- colSums(dtm2)
frequency <- sort(frequency, decreasing = T)
head(frequency)
dim(frequency)
View(dtm2)
Products$word_count <- dtm
Products$word_count <- t(dtm)
Products$review_clean <- removePunctuation(Products$review)
review_text <- paste(Products$review_clean, collapse = ' ')
review_source <- VectorSource(review_text)
corpus <- Corpus(review_source)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus,stripWhitespace)
#corpus <- tm_map(corpus,removeWords, stopwords('english'))
dtm <- DocumentTermMatrix(corpus)
dtm2 <- as.matrix(dtm)
frequency <- colSums(dtm2)
frequency <- sort(frequency, decreasing = T)
head(frequency)
dim(frequency)
Products$word_count <- t(dtm)
requency <- colSums(dtm2)
frequency_sort <- sort(frequency, decreasing = T)
word.freq <- function(document.vector, sparsity = .999)
{
# construct corpus
temp.corpus <- Corpus(VectorSource(document.vector))
# construct tf matrix and remove sparse terms
temp.tf <- DocumentTermMatrix(temp.corpus,
control = list(stopwords = stopwords(’english’),
removeNumbers = T))
temp.tf <- removeSparseTerms(temp.tf, sparsity)
temp.tf <- as.matrix(temp.tf)
# construct word frequency df
freq.df <- colSums(temp.tf)
freq.df <- data.frame(word = names(freq.df), freq = freq.df)
rownames(freq.df) <- NULL
return(freq.df)
}
train_modified <- read.csv("C:/Users/dfoley/Dropbox/Hackathon/Big_Mart_Sales/train_modified.csv")
View(train_modified)
install.packages('caret')
install.packages('Metrics')
library(caret)
library(Metrics)
train<- read.csv("C:/Users/dfoley/Dropbox/Hackathon/Big_Mart_Sales/train_modified.csv")
test <- read.csv("C:/Users/dfoley/Dropbox/Hackathon/Big_Mart_Sales/test_modified.csv")
set.seed(999)
fitControl <- trainControl(method = 'repeatedcv', number =4, repeats = 4)
View(train)
View(test)
View(train)
install.packages('gbm')
library(gbm)
GBM_model = gbm(Item_Outlet_Sales .~ ,data=train,n.trees=50,shrinkage=0.005 ,cv.folds=10)
GBM_model = gbm(Item_Outlet_Sales ~ .,data=train,n.trees=50,shrinkage=0.005 ,cv.folds=10)
predictors <- c('Item_MRP',
'Item_Visibility',
'Item_Weight',
'Item_Visibility_Ratio',
'Outlet_Years',
'Item_Fat_Content_0',
'Item_Fat_Content_1',
'Item_Fat_Content_2',
'Outlet_Location_Type_0',
'Outlet_Location_Type_1',
'Outlet_Location_Type_2',
'Outlet_Size_0',
'Outlet_Size_1',
'Outlet_Size_2',
'Outlet_Type_0',
'Outlet_Type_1',
'Outlet_Type_2',
'Outlet_Type_3',
'Item_Type_Combined_0',
'Item_Type_Combined_1',
'Item_Type_Combined_2',
'Outlet_0',
'Outlet_1',
'Outlet_2',
'Outlet_3',
'Outlet_4',
'Outlet_5',
'Outlet_6',
'Outlet_7',
'Outlet_8',
'Outlet_9')
GBM_model = gbm(Item_Outlet_Sales ~ predictors ,data=train,n.trees=50,shrinkage=0.005 ,cv.folds=10)
View(train)
predictors = train[,-1]
GBM_model = gbm(Item_Outlet_Sales ~ predictors ,data=train,n.trees=50,shrinkage=0.005 ,cv.folds=10)
GBM_model = gbm(Item_Outlet_Sales ~ train[,-1] ,data=train,n.trees=50,shrinkage=0.005 ,cv.folds=10)
GBM_model = gbm(Item_Outlet_Sales ~ formula(train[,-1]) ,data=train,n.trees=50,shrinkage=0.005 ,cv.folds=10)
formula = Item_Outlet_Sales ~ train[,-1]
GBM_model = gbm(formula ,data=train,n.trees=50,shrinkage=0.005 ,cv.folds=10)
View(train)
GBM_model = gbm.fit(x = train[,-1], y = Item_Outlet_Sales ,data=train,n.trees=50,shrinkage=0.005 ,cv.folds=10)
gbm_formula <- as.formula(paste0("Item_Outlet_Sales ~ ", paste(colnames(train[, -1]),
collapse = " + ")))
gbm_formula
GBM_model = gbm.fit(gbm_formula ,data=train,n.trees=50,shrinkage=0.005 ,cv.folds=10)
GBM_model = gbm(gbm_formula ,data=train,n.trees=50,shrinkage=0.005 ,cv.folds=10)
best.iter <- gbm.perf(GBM_model,method="cv")
test_pred <- predict.gbm(GBM_model,test,best.iter)
View(test)
best.iter
predict.gbm(GBM_model,test,best.iter)
test
test$Item_Outlet_Sales
test$Item_Outlet_Sales =  predict.gbm(GBM_model,test,best.iter)
View(test)
predict.gbm(GBM_model,test[,-1],best.iter)
View(train)
summary(GBM_model)
gbm_formula <- as.formula(paste0(Item_Outlet_Sales ~ , paste(colnames(train[, -1]),
collapse = " + ")))
gbm_formula <- as.formula(paste0(Item_Outlet_Sales ~ , paste(colnames(train[, -1]),
collapse = '+'  )))
gbm_formula <- as.formula(paste0(Item_Outlet_Sales ~ , paste(colnames(train[, -1]),collapse = '+'  )))
gbm_formula <- as.formula(paste0('Item_Outlet_Sales ~' ,paste(colnames(train[, -1]),collapse = '+'  )))
gbm_formula
GBM_model = gbm(gbm_formula ,data=train, n.trees=50,shrinkage=0.005 ,cv.folds=10)
GBM_model
GBM_model = gbm(gbm_formula ,data=train, n.trees=50,shrinkage=0.05 ,cv.folds=10)
GBM_model
best.iter <- gbm.perf(GBM_model,method="cv")
summary(GBM_model)
View(train)
gbm_formula <- as.formula(paste0('Item_Outlet_Sales ~' ,paste(colnames(train[, -c(1,3]),collapse = '+'  )))
gbm_formula <- as.formula(paste0('Item_Outlet_Sales ~' ,paste(colnames(train[, -c(1,30)]),collapse = '+'  )))
gbm_formula
GBM_model = gbm(gbm_formula ,data=train, n.trees=50,shrinkage=0.05 ,cv.folds=10)
best.iter <- gbm.perf(GBM_model,method="cv")
summary(GBM_model)
gbm_formula
gbm_formula <- as.formula(paste0('Item_Outlet_Sales ~' ,paste(colnames(train[, -c(1,3)]),collapse = '+'  )))
GBM_model = gbm(gbm_formula ,data=train, n.trees=50,shrinkage=0.05 ,cv.folds=10)
best.iter <- gbm.perf(GBM_model,method="cv")
summary(GBM_model)
test_pred <- predict.gbm(GBM_model,test,best.iter)
test_pred
View(test)
Item_Outlet_Sales <- predict.gbm(GBM_model,test,best.iter)
results <- as.data.frame(cbind(test$Item_Identifier,Item_Outlet_Sales , test$Outlet_Identifier ))
results
setwd("~/Dropbox/Hackathon/Big_Mart_Sales")
setwd("C:/Users/dfoley/Dropbox/Hackathon/Big_Mart_Sales")
write.csv(results, file = 'gbmalg.csv', row.names = False)
write.csv(results, file = 'gbmalg.csv', row.names = FALSE)
View(test)
test$Item_Identifier
test$Outlet_Identifier
Item_Outlet_Sales
cbind(test$Item_Identifier,Item_Outlet_Sales , test$Outlet_Identifier ))
cbind(test$Item_Identifier,Item_Outlet_Sales , test$Outlet_Identifier )
cbind(test$Item_Identifier, test$Outlet_Identifier )
ID <- as.data.frame(test$Item_Identifier)
OutletID <- as.data.frame(test$Outlet_Identifier )
ID
OutletID
result <- as.data.frame(Item_Outlet_Sales)
result
results <- cbind(ID,result ,OutletID )
results
write.csv(results, file = 'gbmalg.csv', row.names = FALSE)
write.csv(results, file = 'gbmalg1.csv', row.names = FALSE)
write.csv(results, file = 'gbmalg1.csv', row.names = FALSE)
head(results)
GBM_model = gbm(gbm_formula ,data=train, n.trees=50,shrinkage=0.05 ,cv.folds=10)
best.iter <- gbm.perf(GBM_model,method="cv")
summary(GBM_model)
Item_Outlet_Sales <- predict.gbm(GBM_model,test,best.iter)
Item_Outlet_Sales
ID <- as.data.frame(test$Item_Identifier)
OutletID <- as.data.frame(test$Outlet_Identifier)
result <- as.data.frame(Item_Outlet_Sales)
head(result)
results <- cbind(ID,result ,OutletID )
head(results)
setwd("C:/Users/dfoley/Dropbox/Hackathon/Big_Mart_Sales")
write.csv(results, file = 'gbmalg2.csv', row.names = FALSE)
