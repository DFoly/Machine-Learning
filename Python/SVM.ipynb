{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text based Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset is collection of frequency of words from emails\n",
    "##and shows whether email is spam or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cant find dataset\n",
    "#data,target = load_svmlight_file('data/E2006.train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import CSV data and put into format we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ifile  = open('spam.csv', \"rb\")\n",
    "reader = csv.reader(ifile)\n",
    "data = []\n",
    "for row in reader:\n",
    "    data.append(row)\n",
    "\n",
    "Header = data[0]\n",
    "data.pop(0)  # pops off 0th element aka the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pd.DataFrame(data, columns=Header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Datapd = pd.read_csv('spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Datapd = pd.DataFrame(data, columns=Header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'word.freq.make', u'word.freq.address', u'word.freq.all',\n",
       "       u'word.freq.3d', u'word.freq.our', u'word.freq.over',\n",
       "       u'word.freq.remove', u'word.freq.internet', u'word.freq.order',\n",
       "       u'word.freq.mail', u'word.freq.receive', u'word.freq.will',\n",
       "       u'word.freq.people', u'word.freq.report', u'word.freq.addresses',\n",
       "       u'word.freq.free', u'word.freq.business', u'word.freq.email',\n",
       "       u'word.freq.you', u'word.freq.credit', u'word.freq.your',\n",
       "       u'word.freq.font', u'word.freq.000', u'word.freq.money',\n",
       "       u'word.freq.hp', u'word.freq.hpl', u'word.freq.george',\n",
       "       u'word.freq.650', u'word.freq.lab', u'word.freq.labs',\n",
       "       u'word.freq.telnet', u'word.freq.857', u'word.freq.data',\n",
       "       u'word.freq.415', u'word.freq.85', u'word.freq.technology',\n",
       "       u'word.freq.1999', u'word.freq.parts', u'word.freq.pm',\n",
       "       u'word.freq.direct', u'word.freq.cs', u'word.freq.meeting',\n",
       "       u'word.freq.original', u'word.freq.project', u'word.freq.re',\n",
       "       u'word.freq.edu', u'word.freq.table', u'word.freq.conference',\n",
       "       u'char.freq.semi', u'char.freq.lparen', u'char.freq.lbrack',\n",
       "       u'char.freq.bang', u'char.freq.dollar', u'char.freq.hash',\n",
       "       u'capital.run.length.average', u'capital.run.length.longest',\n",
       "       u'capital.run.length.total', u'spam', u'rgroup'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Datapd.head()\n",
    "Datapd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to numeric data\n",
    "df = Datapd.convert_objects(convert_numeric=True)\n",
    "#df.head\n",
    "#Datapd.spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to dummy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: spam, dtype: int32"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "spammy = preprocessing.LabelEncoder()\n",
    "df.spam = spammy.fit_transform(df.spam)\n",
    "df.spam[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3656 945\n"
     ]
    }
   ],
   "source": [
    "split = np.random.rand(len(df)) < 0.8\n",
    "Data_train = df[split]\n",
    "Data_test = df[~split]\n",
    "print len(Data_train), len(Data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'word.freq.make', u'word.freq.address', u'word.freq.all',\n",
      "       u'word.freq.3d', u'word.freq.our', u'word.freq.over',\n",
      "       u'word.freq.remove', u'word.freq.internet', u'word.freq.order',\n",
      "       u'word.freq.mail', u'word.freq.receive', u'word.freq.will',\n",
      "       u'word.freq.people', u'word.freq.report', u'word.freq.addresses',\n",
      "       u'word.freq.free', u'word.freq.business', u'word.freq.email',\n",
      "       u'word.freq.you', u'word.freq.credit', u'word.freq.your',\n",
      "       u'word.freq.font', u'word.freq.000', u'word.freq.money',\n",
      "       u'word.freq.hp', u'word.freq.hpl', u'word.freq.george',\n",
      "       u'word.freq.650', u'word.freq.lab', u'word.freq.labs',\n",
      "       u'word.freq.telnet', u'word.freq.857', u'word.freq.data',\n",
      "       u'word.freq.415', u'word.freq.85', u'word.freq.technology',\n",
      "       u'word.freq.1999', u'word.freq.parts', u'word.freq.pm',\n",
      "       u'word.freq.direct', u'word.freq.cs', u'word.freq.meeting',\n",
      "       u'word.freq.original', u'word.freq.project', u'word.freq.re',\n",
      "       u'word.freq.edu', u'word.freq.table', u'word.freq.conference',\n",
      "       u'char.freq.semi', u'char.freq.lparen', u'char.freq.lbrack',\n",
      "       u'char.freq.bang', u'char.freq.dollar', u'char.freq.hash',\n",
      "       u'capital.run.length.average', u'capital.run.length.longest',\n",
      "       u'capital.run.length.total', u'spam', u'rgroup'],\n",
      "      dtype='object')\n",
      "3656\n",
      "Index([u'word.freq.make', u'word.freq.address', u'word.freq.all',\n",
      "       u'word.freq.3d', u'word.freq.our', u'word.freq.over',\n",
      "       u'word.freq.remove', u'word.freq.internet', u'word.freq.order',\n",
      "       u'word.freq.mail', u'word.freq.receive', u'word.freq.will',\n",
      "       u'word.freq.people', u'word.freq.report', u'word.freq.addresses',\n",
      "       u'word.freq.free', u'word.freq.business', u'word.freq.email',\n",
      "       u'word.freq.you', u'word.freq.credit', u'word.freq.your',\n",
      "       u'word.freq.font', u'word.freq.000', u'word.freq.money',\n",
      "       u'word.freq.hp', u'word.freq.hpl', u'word.freq.george',\n",
      "       u'word.freq.650', u'word.freq.lab', u'word.freq.labs',\n",
      "       u'word.freq.telnet', u'word.freq.857', u'word.freq.data',\n",
      "       u'word.freq.415', u'word.freq.85', u'word.freq.technology',\n",
      "       u'word.freq.1999', u'word.freq.parts', u'word.freq.pm',\n",
      "       u'word.freq.direct', u'word.freq.cs', u'word.freq.meeting',\n",
      "       u'word.freq.original', u'word.freq.project', u'word.freq.re',\n",
      "       u'word.freq.edu', u'word.freq.table', u'word.freq.conference',\n",
      "       u'char.freq.semi', u'char.freq.lparen', u'char.freq.lbrack',\n",
      "       u'char.freq.bang', u'char.freq.dollar', u'char.freq.hash',\n",
      "       u'capital.run.length.average', u'capital.run.length.longest',\n",
      "       u'capital.run.length.total'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print Data_train.columns\n",
    "## Create Y and X matrices and drop spam and rgroup from X matrix\n",
    "y = Data_train[['spam']] # seems to be the same as before randomised\n",
    "print len(y)\n",
    "print Data_train.columns[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define as numpy arrays and add column of ones to X\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X = np.insert(X,0,1,1) # add column of ones\n",
    "X = X[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0.0, 0.64, 0.64, 0.0, 0.32, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.64,\n",
       "        0.0, 0.0, 0.0, 0.32, 0.0, 1.29, 1.93, 0.0, 0.96, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.778, 0.0, 0.0, 3.7560000000000002, 61L, 278L],\n",
       "       [1, 0.0, 0.0, 0.0, 0.0, 0.63, 0.0, 0.31, 0.63, 0.31, 0.63, 0.31,\n",
       "        0.31, 0.31, 0.0, 0.0, 0.31, 0.0, 0.0, 3.18, 0.0, 0.31, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.13699999999999998, 0.0, 0.13699999999999998, 0.0, 0.0, 3.537,\n",
       "        40L, 191L],\n",
       "       [1, 0.0, 0.0, 0.0, 0.0, 1.85, 0.0, 0.0, 1.85, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.223, 0.0,\n",
       "        0.0, 0.0, 0.0, 3.0, 15L, 54L],\n",
       "       [1, 0.0, 0.0, 0.0, 0.0, 1.92, 0.0, 0.0, 0.0, 0.0, 0.64, 0.96, 1.28,\n",
       "        0.0, 0.0, 0.0, 0.96, 0.0, 0.32, 3.85, 0.0, 0.64, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.054000000000000006, 0.0, 0.16399999999999998,\n",
       "        0.054000000000000006, 0.0, 1.671, 4L, 112L]], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print X[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we will try Logistic regression manually and then use scikit learn to confirm the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # logistic function, transforms output between 0 and 1\n",
    "    # had to define as numpy float to avoid error\n",
    "    z = np.float64(z)\n",
    "    g = 1/(1+np.exp(-z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0) #  function works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost function $$ J(\\theta) = 1/m \\sum_{i=1}^{m} [-y^{(i)}log(h_{(\\theta)} x^{(i)})- (1-y^{(i)})log(1-h_{(\\theta)}(x^{(i))})]  $$\n",
    "\n",
    "Vectorized: $$  J(\\theta) = 1/m \\hspace{2mm} [log(g(X\\theta)^{T})y + log((1- g(x\\theta))^{T})(1-y)]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CostFunction(theta,X,y):\n",
    "    m = y.size\n",
    "    # hypothesis\n",
    "    h = sigmoid(X.dot(theta))\n",
    "    J = 0\n",
    "    # returns 0 if we dont define m as float\n",
    "    J = (1/float(m)) * (np.log(h).T.dot(y) + np.log(1-h).T.dot(y))\n",
    "    return J\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test sigmoid function\n",
    "sigmoid(X.dot(initial_theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Calculation\n",
    "\n",
    "Partial Derviative\n",
    "$$ \\frac{\\delta J(\\theta)}{\\delta\\theta_{j}} = 1/m \\sum_{i=1}^{m} (h_{\\theta}(x^{i})-y^{(i)})x_{j}^{(i)} $$\n",
    "\n",
    "Vectorised Form\n",
    "$$\\frac{\\delta J(\\theta)}{\\delta\\theta} =  1/m \\hspace{3mm} X^T(h_{\\theta} - y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Grad(theta,X,y):\n",
    "    m = y.size\n",
    "    h = sigmoid(X.dot(theta.reshape(-1,1)))\n",
    "    \n",
    "    grad = (1/float(m)) * X.T.dot(h-y)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cost function and gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: [-0.5467824] \n",
      "\n",
      "Grad:[[  1.05579869e-01]\n",
      " [  1.05579869e-01]\n",
      " [ -6.10913567e-03]\n",
      " [  4.52721554e-02]\n",
      " [ -1.85393873e-02]\n",
      " [ -1.93927790e-02]\n",
      " [ -4.58027899e-02]\n",
      " [ -2.06441466e-02]\n",
      " [ -5.16684902e-02]\n",
      " [ -3.14920678e-02]\n",
      " [ -2.27707877e-02]\n",
      " [ -1.28446389e-02]\n",
      " [ -1.56291028e-02]\n",
      " [  5.40303611e-02]\n",
      " [ -9.74972648e-03]\n",
      " [ -2.85694748e-03]\n",
      " [ -2.00027352e-02]\n",
      " [ -7.84477571e-02]\n",
      " [ -3.76928337e-02]\n",
      " [ -3.35667396e-02]\n",
      " [ -5.98673414e-02]\n",
      " [ -3.72155361e-02]\n",
      " [ -1.42597101e-01]\n",
      " [ -4.41739606e-02]\n",
      " [ -4.83506565e-02]\n",
      " [ -3.68421772e-02]\n",
      " [  2.61788840e-01]\n",
      " [  1.25043764e-01]\n",
      " [  3.84375000e-01]\n",
      " [  5.48864880e-02]\n",
      " [  5.05620897e-02]\n",
      " [  5.00191466e-02]\n",
      " [  3.25738512e-02]\n",
      " [  2.36652079e-02]\n",
      " [  4.48522976e-02]\n",
      " [  2.34286105e-02]\n",
      " [  5.11501641e-02]\n",
      " [  3.79608862e-02]\n",
      " [  5.32973195e-02]\n",
      " [  3.67204595e-03]\n",
      " [  3.76572757e-02]\n",
      " [  1.82904814e-02]\n",
      " [  2.26053063e-02]\n",
      " [  6.64496718e-02]\n",
      " [  1.95910832e-02]\n",
      " [  3.65973742e-02]\n",
      " [  1.06135120e-01]\n",
      " [  8.49439278e-02]\n",
      " [  2.16903720e-03]\n",
      " [  1.33739059e-02]\n",
      " [  1.04325766e-02]\n",
      " [  2.74681346e-02]\n",
      " [  5.22743435e-03]\n",
      " [ -6.36596007e-02]\n",
      " [ -3.09314825e-02]\n",
      " [ -1.05370624e-02]\n",
      " [ -9.18531865e-01]\n",
      " [ -1.35034190e+01]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#initial_theta = np.zeros(X.shape[1])\n",
    "initial_theta.shape\n",
    "Cost = CostFunction(initial_theta,X,y)\n",
    "Grad = Grad(initial_theta, X, y)\n",
    "print('Cost: {} \\n'.format(Cost))\n",
    "print('Grad:{} \\n'.format(Grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(theta,threshold):\n",
    "    p = sigmoid(X.dot(theta)) >= threshold\n",
    "    return(p.astype('int'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minimize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-179-0c5d750ecaa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## minimisation function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcostFunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'maxiter'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'minimize' is not defined"
     ]
    }
   ],
   "source": [
    "## minimisation function\n",
    "res = minimize(costFunction, initial_theta, args=(X,y), method=None, jac=gradient, options={'maxiter':400})\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
